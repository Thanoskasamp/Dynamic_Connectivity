{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb87b61a-d588-41ee-8033-51c08431d6b6",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d2e10-c97d-4f20-abc0-db427de0e393",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198aec09-fe12-462e-af5b-5feeba99fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0781b-9b72-4653-bc72-340dd7242e87",
   "metadata": {},
   "source": [
    "### Load Connectivity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29d5278-9605-4b56-950c-680fc8281d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1         2         3         4         5         6         7  \\\n",
      "1    0.000033  0.000033  1.088253  0.272063  0.120917  0.068016  0.000033   \n",
      "2    0.000028  0.000028  0.000028  0.919358  0.229840  0.102151  2.758201   \n",
      "3    0.871399  0.000026  0.000026  0.000026  0.871399  0.217850  0.373455   \n",
      "4    0.222155  0.888621  0.000027  0.000027  0.000027  0.888621  0.140307   \n",
      "5    0.109651  0.246715  0.986860  0.000030  0.000030  0.000030  0.080017   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "649  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "650  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "651  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "652  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "653  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "            8         9        10  ...       644       645       646  \\\n",
      "1    0.000033  3.264908  0.466393  ...  0.000000  0.000000  0.000000   \n",
      "2    0.000028  0.000028  2.758201  ...  0.000000  0.000000  0.000000   \n",
      "3    2.614316  0.000026  0.000026  ...  0.000000  0.000000  0.000000   \n",
      "4    0.380836  2.665984  0.000027  ...  0.000000  0.000000  0.000000   \n",
      "5    0.155818  0.422938  2.960714  ...  0.000000  0.000000  0.000000   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "649  0.000000  0.000000  0.000000  ...  0.050924  0.090531  0.203696   \n",
      "650  0.000000  0.000000  0.000000  ...  0.032796  0.051244  0.091100   \n",
      "651  0.000000  0.000000  0.000000  ...  0.023281  0.033525  0.052383   \n",
      "652  0.000000  0.000000  0.000000  ...  0.018541  0.025237  0.036341   \n",
      "653  0.000000  0.000000  0.000000  ...  0.017299  0.022595  0.030754   \n",
      "\n",
      "          647       648       649       650       651       652       653  \n",
      "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "649  0.814783  0.000024  0.000024  0.000024  0.814783  0.203696  0.090531  \n",
      "650  0.204975  0.819901  0.000025  0.000025  0.000025  0.819901  0.204975  \n",
      "651  0.093125  0.209531  0.838124  0.000025  0.000025  0.000025  0.838124  \n",
      "652  0.056783  0.100947  0.227132  0.908527  0.000027  0.000027  0.000027  \n",
      "653  0.044286  0.069197  0.123017  0.276788  1.107150  0.000033  0.000033  \n",
      "\n",
      "[653 rows x 653 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load connectivity matrix from CSV\n",
    "connect_matrix = pd.read_csv(\"hexFlow.csv\", sep=\",\",index_col=0)\n",
    "print(connect_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990504b9-de5e-4ed4-a3f9-e8a174ce8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 1st column because it sesrves as an index and it's not needed\n",
    "connect_matrix = connect_matrix.iloc[:, 1:]\n",
    "print(connect_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50da1c-baf1-4f92-8c66-4cb078e0a682",
   "metadata": {},
   "source": [
    "# Transition Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af02bc6-82dd-4794-822a-f5d23aa97423",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e5bd80-633b-4aac-ab0d-b8f5bd137230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize rows\n",
    "def normalize_rows(df):\n",
    "    row_sums = df.sum(axis=1)\n",
    "    normalized_df = df.div(row_sums, axis=0)\n",
    "    return normalized_df\n",
    "\n",
    "# Normalize the connectivity matrix\n",
    "nor_matrix = normalize_rows(connect_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16acbb3-56ce-4fd5-b828-4bea3ab5ae54",
   "metadata": {},
   "source": [
    "#### Verifications of Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4308b162-741c-453f-b4ae-7937e452d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      1.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "5      1.0\n",
      "      ... \n",
      "649    1.0\n",
      "650    1.0\n",
      "651    1.0\n",
      "652    1.0\n",
      "653    1.0\n",
      "Length: 653, dtype: float64\n",
      "(653, 653)\n",
      "0.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Verify that each row sums to 1\n",
    "row_sums = nor_matrix.sum(axis=1)\n",
    "print(row_sums)  # Should print a Series of 1s\n",
    "\n",
    "# Dimensions\n",
    "print(nor_matrix.shape)\n",
    "\n",
    "# Non-Negative Values\n",
    "print(nor_matrix.min().min())\n",
    "\n",
    "# Check if the row names and column names are the same\n",
    "print(nor_matrix.index.equals(nor_matrix.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf08665-ba11-43f4-83ee-c932ad4f87d0",
   "metadata": {},
   "source": [
    "# Initial states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1833e7-3b3a-472b-9833-332461a26bff",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbbd28b5-4c9e-41ac-aad0-a7d328114152",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_planning_units = gpd.read_file(\"hex_planning_units.shp\")\n",
    "\n",
    "# Renaming 'FID' to 'id' and incrementing by 1\n",
    "hex_planning_units = hex_planning_units.rename(columns={'FID': 'id'})\n",
    "hex_planning_units['id'] = hex_planning_units['id'].astype(int) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da0f99-17a9-4599-9305-2fcdd291eec0",
   "metadata": {},
   "source": [
    "### Initial states list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6c79f2-4bf5-44b0-b051-f320432e226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed BIORE_102 as initial state.\n",
      "Processed BIORE_103 as initial state.\n",
      "Processed BIORE_114 as initial state.\n",
      "Processed BIORE_116 as initial state.\n",
      "Processed BIORE_117 as initial state.\n",
      "Processed BIORE_118 as initial state.\n",
      "Processed BIORE_119 as initial state.\n",
      "Processed BIORE_121 as initial state.\n",
      "Processed BIORE_13 as initial state.\n",
      "Processed BIORE_132 as initial state.\n",
      "Processed BIORE_142 as initial state.\n",
      "Processed BIORE_147 as initial state.\n",
      "Processed BIORE_15 as initial state.\n",
      "Processed BIORE_16 as initial state.\n",
      "Processed BIORE_23 as initial state.\n",
      "Processed BIORE_26 as initial state.\n",
      "Processed BIORE_27 as initial state.\n",
      "Processed BIORE_29 as initial state.\n",
      "Processed BIORE_3 as initial state.\n",
      "Processed BIORE_4 as initial state.\n"
     ]
    }
   ],
   "source": [
    "# Get the names of all columns that start with \"BIORE\"\n",
    "biore_columns = [col for col in hex_planning_units.columns if col.startswith(\"BIORE\")]\n",
    "\n",
    "# Create a dictionary to store the normalized initial states for each BIORE column\n",
    "initial_states = {}\n",
    "\n",
    "# Loop through each BIORE column\n",
    "for biore_col in biore_columns:\n",
    "    \n",
    "    # Extract the column into a vector and handle NA values, ensuring non-negative entries\n",
    "    biore_vector = hex_planning_units[biore_col].fillna(0).clip(lower=0)\n",
    "    \n",
    "    # Transform the vector into a row vector\n",
    "    biore_row = biore_vector.values.reshape(1, -1)\n",
    "    \n",
    "    # Ensure the row vector's column names match those of the transition matrix (nor_matrix)\n",
    "    biore_row_df = pd.DataFrame(biore_row, columns=nor_matrix.columns)\n",
    "    \n",
    "    # Rename the row to match the column name\n",
    "    biore_row_df.index = [biore_col]\n",
    "    \n",
    "    # Check if the initial state distribution has the correct dimensions and non-negative values\n",
    "    if biore_row_df.shape[1] != nor_matrix.shape[1]:\n",
    "        raise ValueError(f\"The initial state distribution for {biore_col} does not have the correct number of columns.\")\n",
    "    if (biore_row_df < 0).any().any():\n",
    "        raise ValueError(f\"Some entries in the initial distribution for {biore_col} are negative.\")\n",
    "    \n",
    "    # Normalize the initial distribution so that the sum is 1\n",
    "    biore_row_normalized = biore_row_df.div(biore_row_df.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Ensure that the normalized distribution sums to 1\n",
    "    if not np.isclose(biore_row_normalized.sum(axis=1), 1).all():\n",
    "        raise ValueError(f\"The normalized initial state distribution for {biore_col} does not sum to 1.\")\n",
    "    \n",
    "    # Store the normalized row vector in the initial_states dictionary\n",
    "    initial_states[biore_col] = biore_row_normalized\n",
    "    \n",
    "    # Print a message indicating completion for each column\n",
    "    print(f\"Processed {biore_col} as initial state.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea0517-2167-4d87-837c-abbcb93561e8",
   "metadata": {},
   "source": [
    "### Verification of Initial States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d8822-18f2-435d-98b5-d1e72289224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Structure of initial_states:\")\n",
    "for key, value in initial_states.items():\n",
    "    print(f\"{key}: shape {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcba4b8-8015-4a97-a4ee-9fdea96a25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing a specific BIORE column, e.g., BIORE_147\n",
    "print(\"Viewing initial_states for BIORE_147:\")\n",
    "print(initial_states['BIORE_147'])\n",
    "\n",
    "# Printing another specific BIORE column, e.g., BIORE_102\n",
    "print(\"Initial state distribution for BIORE_102:\")\n",
    "print(initial_states['BIORE_102'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39ce25-e30b-4023-904b-8f89441fe0e8",
   "metadata": {},
   "source": [
    "# Dynamic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f889da5-9a63-4440-a32a-a03043379e95",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aed730c-6df5-4ede-9745-b7a3d56bda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the data frames for each feature\n",
    "iterations_results = {}\n",
    "\n",
    "# Define tolerance for steady-state convergence\n",
    "tolerance = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c382d-8b10-41ce-bd06-2f2e06216ca1",
   "metadata": {},
   "source": [
    "###  Loop Through Each Feature's Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f2fdaa-ab56-4cb5-a1e9-d2fe9aafeb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed BIORE_102 in 470 iterations\n",
      "Processed BIORE_103 in 488 iterations\n",
      "Processed BIORE_114 in 242 iterations\n",
      "Processed BIORE_116 in 462 iterations\n",
      "Processed BIORE_117 in 367 iterations\n",
      "Processed BIORE_118 in 468 iterations\n",
      "Processed BIORE_119 in 448 iterations\n",
      "Processed BIORE_121 in 439 iterations\n",
      "Processed BIORE_13 in 486 iterations\n",
      "Processed BIORE_132 in 482 iterations\n",
      "Processed BIORE_142 in 398 iterations\n",
      "Processed BIORE_147 in 428 iterations\n",
      "Processed BIORE_15 in 411 iterations\n",
      "Processed BIORE_16 in 423 iterations\n",
      "Processed BIORE_23 in 439 iterations\n",
      "Processed BIORE_26 in 409 iterations\n",
      "Processed BIORE_27 in 430 iterations\n",
      "Processed BIORE_29 in 448 iterations\n",
      "Processed BIORE_3 in 454 iterations\n",
      "Processed BIORE_4 in 420 iterations\n"
     ]
    }
   ],
   "source": [
    "for feature_name, previous_state in initial_states.items():\n",
    "    previous_state = previous_state.values.flatten()\n",
    "    current_state = previous_state.copy()\n",
    "    \n",
    "    # Initialize a list to hold each step's data\n",
    "    steps_data = [previous_state]  # Start with the initial state\n",
    "    \n",
    "    iterations = 0\n",
    "    while True:\n",
    "        current_state = np.dot(previous_state, nor_matrix.values)\n",
    "        steps_data.append(current_state)  # Append current state to the list\n",
    "        \n",
    "        iterations += 1\n",
    "        if np.sum(np.abs(current_state - previous_state)) < tolerance:\n",
    "            break\n",
    "        previous_state = current_state\n",
    "\n",
    "    # After the loop, convert the list of numpy arrays into a DataFrame\n",
    "    feature_df = pd.DataFrame(steps_data).T  # Transpose to match your original format\n",
    "    feature_df.columns = [f\"Step_{i}\" for i in range(iterations + 1)]  # Naming columns after steps\n",
    "    \n",
    "    iterations_results[feature_name] = feature_df\n",
    "    print(f\"Processed {feature_name} in {iterations} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e82b21-0ab8-4973-ab13-8d3b179f6207",
   "metadata": {},
   "source": [
    "### Verification of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22337c2-c02c-4065-8094-0dee427d337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for BIORE_102:\n",
      "   Step_0  Step_1  Step_2        Step_3        Step_4        Step_5  \\\n",
      "0     0.0     0.0     0.0  2.464406e-09  1.854455e-08  6.618710e-08   \n",
      "1     0.0     0.0     0.0  1.822032e-09  1.551079e-08  5.902603e-08   \n",
      "2     0.0     0.0     0.0  1.333151e-09  1.255032e-08  5.002717e-08   \n",
      "3     0.0     0.0     0.0  9.538688e-10  9.929398e-09  4.118256e-08   \n",
      "4     0.0     0.0     0.0  6.373710e-10  7.555161e-09  3.248779e-08   \n",
      "\n",
      "         Step_6        Step_7        Step_8        Step_9  ...  Step_461  \\\n",
      "0  1.691110e-07  3.547735e-07  6.521282e-07  1.089787e-06  ...  0.000762   \n",
      "1  1.573355e-07  3.405734e-07  6.416164e-07  1.093860e-06  ...  0.000902   \n",
      "2  1.374896e-07  3.045203e-07  5.843339e-07  1.011462e-06  ...  0.000952   \n",
      "3  1.161304e-07  2.621655e-07  5.107394e-07  8.951575e-07  ...  0.000933   \n",
      "4  9.345664e-08  2.139424e-07  4.213439e-07  7.450970e-07  ...  0.000840   \n",
      "\n",
      "   Step_462  Step_463  Step_464  Step_465  Step_466  Step_467  Step_468  \\\n",
      "0  0.000762  0.000762  0.000763  0.000763  0.000763  0.000763  0.000763   \n",
      "1  0.000902  0.000903  0.000903  0.000903  0.000903  0.000903  0.000903   \n",
      "2  0.000952  0.000952  0.000952  0.000952  0.000952  0.000953  0.000953   \n",
      "3  0.000934  0.000934  0.000934  0.000934  0.000934  0.000934  0.000934   \n",
      "4  0.000841  0.000841  0.000841  0.000841  0.000841  0.000841  0.000841   \n",
      "\n",
      "   Step_469  Step_470  \n",
      "0  0.000763  0.000763  \n",
      "1  0.000903  0.000903  \n",
      "2  0.000953  0.000953  \n",
      "3  0.000934  0.000934  \n",
      "4  0.000841  0.000841  \n",
      "\n",
      "[5 rows x 471 columns]\n",
      "Feature data frame: BIORE_102\n",
      "Feature data frame: BIORE_103\n",
      "Feature data frame: BIORE_114\n",
      "Feature data frame: BIORE_116\n",
      "Feature data frame: BIORE_117\n",
      "Feature data frame: BIORE_118\n",
      "Feature data frame: BIORE_119\n",
      "Feature data frame: BIORE_121\n",
      "Feature data frame: BIORE_13\n",
      "Feature data frame: BIORE_132\n",
      "Feature data frame: BIORE_142\n",
      "Feature data frame: BIORE_147\n",
      "Feature data frame: BIORE_15\n",
      "Feature data frame: BIORE_16\n",
      "Feature data frame: BIORE_23\n",
      "Feature data frame: BIORE_26\n",
      "Feature data frame: BIORE_27\n",
      "Feature data frame: BIORE_29\n",
      "Feature data frame: BIORE_3\n",
      "Feature data frame: BIORE_4\n"
     ]
    }
   ],
   "source": [
    "# Example: Access the DataFrame for BIORE_102\n",
    "if \"BIORE_102\" in iterations_results:\n",
    "    print(\"Data for BIORE_102:\")\n",
    "    print(iterations_results[\"BIORE_102\"].head())  # Using .head() to print the first few rows\n",
    "\n",
    "# Loop through the names and print each one\n",
    "for feature_name, df in iterations_results.items():\n",
    "    print(f\"Feature data frame: {feature_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe215b-7a71-4a40-88e1-9eff74bbec66",
   "metadata": {},
   "source": [
    "### Step sums Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6cd9a1f-76c1-471c-a8b0-c6012abf8ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed sum for feature: BIORE_102\n",
      "Computed sum for feature: BIORE_103\n",
      "Computed sum for feature: BIORE_114\n",
      "Computed sum for feature: BIORE_116\n",
      "Computed sum for feature: BIORE_117\n",
      "Computed sum for feature: BIORE_118\n",
      "Computed sum for feature: BIORE_119\n",
      "Computed sum for feature: BIORE_121\n",
      "Computed sum for feature: BIORE_13\n",
      "Computed sum for feature: BIORE_132\n",
      "Computed sum for feature: BIORE_142\n",
      "Computed sum for feature: BIORE_147\n",
      "Computed sum for feature: BIORE_15\n",
      "Computed sum for feature: BIORE_16\n",
      "Computed sum for feature: BIORE_23\n",
      "Computed sum for feature: BIORE_26\n",
      "Computed sum for feature: BIORE_27\n",
      "Computed sum for feature: BIORE_29\n",
      "Computed sum for feature: BIORE_3\n",
      "Computed sum for feature: BIORE_4\n",
      "First few rows of the final_markov DataFrame:\n",
      "   BIORE_102  BIORE_103  BIORE_114  BIORE_116  BIORE_117  BIORE_118  \\\n",
      "1   0.315301   0.316870   0.211033   0.313959   0.275610   0.314749   \n",
      "2   0.332304   0.333958   0.222250   0.330887   0.290428   0.331721   \n",
      "3   0.325614   0.327236   0.217655   0.324225   0.284549   0.325042   \n",
      "4   0.293019   0.294480   0.195776   0.291768   0.256042   0.292504   \n",
      "5   0.222880   0.223991   0.148906   0.221929   0.194755   0.222488   \n",
      "\n",
      "   BIORE_119  BIORE_121  BIORE_13  BIORE_132  ...  BIORE_147  BIORE_15  \\\n",
      "1   0.503575   0.485209  0.316145   0.316443  ...   0.492464  0.299702   \n",
      "2   0.530186   0.512256  0.333193   0.333508  ...   0.522356  0.315845   \n",
      "3   0.519057   0.502674  0.326486   0.326795  ...   0.506775  0.309474   \n",
      "4   0.466791   0.452886  0.293804   0.294082  ...   0.453806  0.278485   \n",
      "5   0.354870   0.344656  0.223477   0.223689  ...   0.344798  0.211826   \n",
      "\n",
      "   BIORE_16  BIORE_23  BIORE_26  BIORE_27  BIORE_29   BIORE_3   BIORE_4  id  \n",
      "1  0.443242  0.310597  0.298145  0.468754  0.498706  0.313053  0.440884   1  \n",
      "2  0.467052  0.327337  0.314203  0.495561  0.525656  0.329932  0.465050   2  \n",
      "3  0.457565  0.320740  0.307863  0.486984  0.515121  0.323288  0.456023   3  \n",
      "4  0.411704  0.288628  0.277036  0.438908  0.464805  0.290925  0.410629   4  \n",
      "5  0.313103  0.219539  0.210723  0.334268  0.352318  0.221287  0.312421   5  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataFrame with an index that matches the expected range of IDs\n",
    "final_markov = pd.DataFrame(index=np.arange(1, 654))  # np.arange starts at 1 and ends at 653 inclusive\n",
    "\n",
    "# Loop through each BIORE feature in the iterations_results dictionary\n",
    "for feature_name, biore_df in iterations_results.items():\n",
    "    \n",
    "    # Exclude 'Step_0' and sum the rest of the steps (Step_1, Step_2, ..., Step_N)\n",
    "    steps_columns = [col for col in biore_df.columns if \"Step_\" in col and col != \"Step_0\"]\n",
    "\n",
    "    # Create a new column 'Step_Sum' that sums all the remaining Step columns\n",
    "    biore_sum = biore_df[steps_columns].sum(axis=1)\n",
    "\n",
    "    # Add this sum as a new column in the final_markov DataFrame, with the column named after the BIORE feature\n",
    "    final_markov[feature_name] = biore_sum\n",
    "\n",
    "    # Print a message indicating the sum is computed for this feature\n",
    "    print(f\"Computed sum for feature: {feature_name}\")\n",
    "\n",
    "# Add the 'id' column with values from 1 to 653\n",
    "final_markov['id'] = np.arange(1, 654)\n",
    "\n",
    "# Print the first few rows of the final_markov DataFrame\n",
    "print(\"First few rows of the final_markov DataFrame:\")\n",
    "print(final_markov.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce334aec-f1f8-411e-ba55-315168f1831c",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad766e-a8ba-43bb-9b89-9bf08386ee66",
   "metadata": {},
   "source": [
    "### Rasterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a696d67-9fc3-497a-8134-7db621b8958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: BIORE_102\n",
      "Processing feature: BIORE_103\n",
      "Processing feature: BIORE_114\n",
      "Processing feature: BIORE_116\n",
      "Processing feature: BIORE_117\n",
      "Processing feature: BIORE_118\n",
      "Processing feature: BIORE_119\n",
      "Processing feature: BIORE_121\n",
      "Processing feature: BIORE_13\n",
      "Processing feature: BIORE_132\n",
      "Processing feature: BIORE_142\n",
      "Processing feature: BIORE_147\n",
      "Processing feature: BIORE_15\n",
      "Processing feature: BIORE_16\n",
      "Processing feature: BIORE_23\n",
      "Processing feature: BIORE_26\n",
      "Processing feature: BIORE_27\n",
      "Processing feature: BIORE_29\n",
      "Processing feature: BIORE_3\n",
      "Processing feature: BIORE_4\n"
     ]
    }
   ],
   "source": [
    "def create_multilayer_raster(final_markov, hex_planning_units):\n",
    "    resolution = 1000\n",
    "    bounds = hex_planning_units.total_bounds\n",
    "    height = int((bounds[3] - bounds[1]) / resolution)\n",
    "    width = int((bounds[2] - bounds[0]) / resolution)\n",
    "    transform = from_origin(bounds[0], bounds[3], resolution, resolution)\n",
    "\n",
    "    raster_dict = {}\n",
    "\n",
    "    # Loop through each BIORE_ feature in final_markov (excluding 'id' column)\n",
    "    for feature_name in final_markov.columns.drop('id'):\n",
    "        print(f\"Processing feature: {feature_name}\")\n",
    "        \n",
    "        # Merge hex_planning_units with current BIORE feature data\n",
    "        biore_data = final_markov[['id', feature_name]]\n",
    "        hex_data = hex_planning_units[['geometry']].merge(biore_data, left_on=hex_planning_units.index, right_on='id', how='left')\n",
    "\n",
    "        # Rasterize the summed data for the current BIORE feature\n",
    "        rasterized = rasterize(\n",
    "            [(geom, value) for geom, value in zip(hex_data.geometry, hex_data[feature_name])],\n",
    "            out_shape=(height, width),\n",
    "            fill=np.nan,\n",
    "            transform=transform,\n",
    "            dtype='float32'\n",
    "        )\n",
    "\n",
    "        # Normalize raster values for better visualization\n",
    "        valid_mask = ~np.isnan(rasterized)\n",
    "        if np.any(valid_mask):\n",
    "            min_val = np.nanmin(rasterized[valid_mask])\n",
    "            max_val = np.nanmax(rasterized[valid_mask])\n",
    "            normalized_raster = (rasterized - min_val) / (max_val - min_val)\n",
    "\n",
    "        raster_dict[feature_name] = normalized_raster\n",
    "\n",
    "    return raster_dict\n",
    "\n",
    "# Function call\n",
    "raster_dict = create_multilayer_raster(final_markov, hex_planning_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b610afa-b977-4f7c-885c-62a0f7421688",
   "metadata": {},
   "source": [
    "###  Dynamic PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c79b7847-c6a5-49f2-bc4f-b3ecd21fad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All raster images have been saved in dynamic_results.\n"
     ]
    }
   ],
   "source": [
    "# Create the directory for saving PNG files if it doesn't exist\n",
    "output_directory = \"dynamic_results\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Plotting each raster from raster_dict and saving as PNG\n",
    "for feature_name, raster in raster_dict.items():\n",
    "    # Create a new figure for each plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))  # Adjust the size based on your needs\n",
    "    ax.set_title(feature_name)\n",
    "    raster_img = ax.imshow(raster, cmap='viridis', extent=hex_planning_units.total_bounds[[0, 2, 1, 3]])\n",
    "    hex_planning_units.boundary.plot(ax=ax, edgecolor='lightgray', linewidth=0.5)\n",
    "    fig.colorbar(raster_img, ax=ax, label='Normalized Value')\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"{output_directory}/{feature_name}.png\")\n",
    "    plt.close(fig)  # Close the plot to free up memory\n",
    "\n",
    "print(f\"All raster images have been saved in {output_directory}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebea13-33fc-4c76-a2ff-91e9bf220789",
   "metadata": {},
   "source": [
    "### Dynamic GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05c9358-add9-471a-8c24-9b469c0d58a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved individual layer as TIF: GeoTIFF\\BIORE_102.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_103.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_114.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_116.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_117.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_118.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_119.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_121.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_13.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_132.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_142.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_147.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_15.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_16.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_23.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_26.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_27.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_29.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_3.tif\n",
      "Saved individual layer as TIF: GeoTIFF\\BIORE_4.tif\n"
     ]
    }
   ],
   "source": [
    "def save_individual_rasters_to_tif(raster_dict, hex_planning_units, output_dir='GeoTIFF'):\n",
    "    # Ensure the output directory exists; if not, create it\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Get the bounds and resolution from hex_planning_units\n",
    "    bounds = hex_planning_units.total_bounds  # [min_x, min_y, max_x, max_y]\n",
    "    resolution = 1000  # Adjust resolution if needed\n",
    "    transform = from_origin(bounds[0], bounds[3], resolution, resolution)  # Top-left corner and resolution\n",
    "\n",
    "    # Loop through each raster in the dictionary and save as separate TIF files\n",
    "    for layer_name, raster_data in raster_dict.items():\n",
    "        # Create a unique filename for each layer\n",
    "        output_file = os.path.join(output_dir, f\"{layer_name}.tif\")\n",
    "        \n",
    "        # Define the new dataset's metadata\n",
    "        with rasterio.open(\n",
    "            output_file, 'w', driver='GTiff',\n",
    "            height=raster_data.shape[0], width=raster_data.shape[1],\n",
    "            count=1, dtype=str(raster_data.dtype),\n",
    "            crs=hex_planning_units.crs.to_string(),  # Use CRS from hex_planning_units\n",
    "            transform=transform\n",
    "        ) as new_dataset:\n",
    "            # Write the raster data to the file\n",
    "            new_dataset.write(raster_data, 1)\n",
    "            print(f\"Saved individual layer as TIF: {output_file}\")\n",
    "\n",
    "# Example function call to save each raster as separate TIF files in 'GeoTIFF' folder\n",
    "save_individual_rasters_to_tif(raster_dict, hex_planning_units, 'GeoTIFF')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
